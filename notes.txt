normal shadowpass

v2f vert(appdata_base v)
            {
                v2f o;
                TRANSFER_SHADOW_CASTER_NORMALOFFSET(o)
                return o;
            }

just do your custom vertices before that and it will work:

v2f vert(appdata_base v)
            {
                float4 worldPos = mul(_Object2World, v.vertex);
                // do stuff to worldPos.xyz
                v.vertex = mul(_World2Object, worldPos);
                v2f o;
                TRANSFER_SHADOW_CASTER_NORMALOFFSET(o)
                return o;
            }

here, he is turning the vertices to world coordinates and then back to object coordinates.
_Object2World is M matrix as I understand it.
so we're taking model coordinates * M to get their position in world space.

TRANSFER_SHADOW_CASTER_NORMALOFFSET

#define TRANSFER_SHADOW_CASTER_NOPOS(o,opos) 
o.vec = mul(unity_ObjectToWorld, v.vertex).xyz - _LightPositionRange.xyz; 
opos = UnityObjectToClipPos(v.vertex);

so transfer shadow caster is taking object to world coordinates for the light position calculation,
then it sets position to UnityObjectToClipPos
This is the equivalent of mul(UNITY_MATRIX_MVP, float4(pos, 1.0)), and should be used in its place.

so clearly, TRANSFER_SHADOW_CASTER is assuming model vertices coordinates.

very similar to our billboard code, but the major difference is that in the sprite renderer,
we start from model vertices and want to end on clip coordinates, so we basically do
MVP * vertices
with some modification for billboarding

in the shadow caster example it's not as simple. we instead must start from model coordinates,
modify them to billboard, then return to model coordinates.


       M       V          P
model -> world -> camera -> clip space


possibility 1: do TRANSFER_SHADOW_CASTER_NORMALOFFSET manually with billboarding enabled.
possibility 2: perform some sort of billboarding in world space or whatever, then transform back.

billboard:

float xscale = length(unity_ObjectToWorld._m00_m10_m20);

float4 view = mul(
                UNITY_MATRIX_MV, 
                float4(0, vertex.y, 0.0, 1.0)
            ) + float4(vertex.x * xscale, 0.0, 0.0, 0.0);

pos = mul(
    UNITY_MATRIX_P, 
    view 
);

why does this work at all? we are basically multiplying the x coordinate straight from model to clip

✓ reformulate in 64x64
    ✓ new sprites
        ✓ base
        ✓ pistol
        ✓ smg
        ✓ shotgun
        ✓ rifle
    ✓ new models: not necessary
    ✓ new textures
        ✓ windows
        ✓ street parking sign
        ✓ gibs 
        ✓ shells
        ✓ decals
        ✓ newspaper stand
        ✓ sidewalk
        ✓ pc tower / monitor
        ✓ fence
        ✓ meter wires
        ✓ emission map

UI initiative
    probably i want pixelated / animated lines and callouts

interactible
    press F to interact with nearest 
    UI call-out of F action

how can we highlight when an object is near?
    needs to detect objects in range and sort by priority
        is this a case for a tag?
        a trigger collider, masked to collide with only certain layer objects
        what about don't hide interlopers?
    UI needs to bind to interactor

broadly:
interactive interface is in place.
we next need to think about how hacking interacts with this system.

* graphics
    pass 2 of base template
    security guard
    face
* UI   
    better gun / item graphics
* hacking
    networks / gateways / endpoints
    UI overlay
    clarity 
* level parameters
    sound effects, camera defaults, etc.
    scenes
    objectives
* system
    main menu
    game start
    game load
    settings
* entities
    baddies
    civilians
    robots
    AI
* more environment



time to speculate on some new gameplay beats. try to narrow in on what drew me to this idea.
overall theme possibilities:
    1. realistic B&E simulator. buildings have realistic utilities, firefighter access, security grids, physical security. you need specialized tools and tactics to get around.
    2. modern setting / cyberpunk setting / sci-fi setting
        shadowrun SNES: alleyways, brick buildings
    3. stealth ninja
        stealth kills with sword, knife, etc.
    4. whatever DJ1 was
            DJ1 was: flat concrete plains with small buildings dotting it. like military compounds.
            instead we want:
                self contained small office tower (say 3 story building) with interior, exterior, multiple insertion / extraction points.

inspo:
    ghost in the shell

the basic loop: do missions, earn credits, buy upgrades, do harder missions
    some very hard missions might be available early on, technically doable with pure stealth?

an alarm is triggered and the street fills up with private securiy swat response team (configurable offsite secutiy detail per level)
    the team lines up outside and then breaches through main entrance
an alarm is triggered and shutter doors descend, corridor fills with gas, turrets pop out of walls

you sneak through a ventilation airduct until you're above the conference room containing your target, bypassing the security detail and locked door outside.
you drop down through the vent and quickly dispatch everyone inside with throwing stars and nanoblade katana. the guards outside the door hear nothing and you commence extraction.
outside the window, the city night twinkles like fireflies in the darkness. your home is down there: safely in the shadows.

breaching a conference room, shooting the target with delayed-explosive tip flechettes

shellfish toxin flechettes / needlegun

you plant remote detonation explosives outside a wall in the alley way first thing, so that you'll have a quick escape route later. after you have completed the mission objectives, security is closing in:
so you hit the detonator and make for the hole in the wall.

planting explosives or a simulator / distractor outside, to draw the security team away from your target.

a team of two men in hazmat suits carry a radioactive thing through a cleanroom hallway

MI CIA NOC list sequence (disguise, trigger alarms, distract, track, etc.)

at the first sign of trouble, a team of bodyguards shove the VIP into a bulletproof limo and then take defensive positions

you approach a smart gas meter. interact brings up a live close-up cam with greater detail. you use a toolbox of tools to unscrew faceplates,
snip wires, attach hacking gizmos, enter the network, etc.

randomized missions

hack or tap security system to get a UI feed of their info & actions

shooting out a fine wire zipline into the neck of a distracted robot to upload a stun program that disables it temporarily

remote hacker handles hacking things for you
a fence for handling stolen goods & data

ransacking storage for valuable equipment?

overall, a sense of *precision and detail*

something like: hitman, but *not* scripted predetermined bullshit! instead, planning ahead, using an array of tools, realistic tactics, planning entrance and escape routes,
using what you've unlocked to access better ingress points (grapple gun, dropship), in a sort of immersive sim that takes care of realistic response to your actions.
each time it unfolds differently.
realistic security response.
    * something is amiss on the secutity cam (body, missing guard)
    * a guard has been out of communication for some time
    * perimiter alarm has been triggered

ironman mode?
abort mission?



incongruities with vision:
1. control 
    feels too loose?
    sticky controls: actual unity bug, submit bug report
2. shadows
    shadows should be more congruent with expected feel
    shadows on sprite should be darker
    easy to hide in, like thief
        use shadowprobe to create a transparent overlay?
        prevents nice dynamic shadows / light effects?
    i want deep shadows near planters and structures
        dark, gritty
        shadows don't apply correctly
        shadow probe doesnt change much in dark regions
    post-processing: increase contrast? dynamic?

head:
1. clamp head angle
2. don't apply head angle when moving
3. hide during forbidden animations
4. adjust gun spritesheets



ENUM            clamp       result
0 - left                    0
1 - leftup      X           1 <- clamp
2 - up                      2
3 - rightup                 3 <- upper
4 - right                   3
5 - rightdown               3/7
6 - down                    7
7 - leftdown                7 <- lower (-1)

7 - 4 = 3
3 / 2 = 1.5


ENUM            clamp       result
0 - left                    2/6
1 - leftup                  2
2 - up                      2 <- lower
3 - rightup                 3
4 - right       X           4 <- clamp
5 - rightdown               5
6 - down                    6 <- upper
7 - leftdown                6



ENUM            clamp       result
0 - left         X          0 <- clamp
1 - leftup                  1
2 - up                      2 <- upper
3 - rightup                 3
4 - right                   3/6
5 - rightdown               6
6 - down                    6 <- lower
7 - leftdown                7


next major branches to work on:

NPCs
    sphere robot
    basic civilians
        hands up pose
        animation temp frame
            hand interact pose
        damage
        gibbing
interactives
    PIP camera for panel interactions system
        take control mode
        layer visible only to cinematic camera
        camera lerp in / out on enter/exit
        UI contains PIP camera while active
        modular interactive panel system
            tool kit
                screwdriver, lockpicks, wire cutters, cyberdeck
            open up panel
            wires to cut
            data port to tap
            physical locks
            variable effects
                overload, bypass, reroute, etc.
                terminator-style hack card for ATM
environmental systems
    power
        lights, various gadgets receive power / no power
        dynamic lights / instanced material emission
        backup generator
        mains connection / transformer
        underground cables / steam tunnels
        UI representation of power network?

    network
        hacking system
            WAN / cloud connection on map
        allow hacking over networks
        routers / portals
        firewalls
        ICE
    alarms / video feed ?
    water / fire suppression ?

    represent the connections physically in-game
        automatically represent the connectors as meshes in-game?
        different vision modes can reveal infrastructure connections
        connections are severed when wall explodes
            water pipes spill water
            network connections severed
police / security response


camera
broadly, inputs are created depending on state, then camera applies input by lerping


1. on power change
2. power source on / off
3. easier way to hook up power grids
4. power grid UI layer
    iconography

Under the name ‘Livre des figures hiéroglyphiques’ The depictions were meant to be painted on an arch in Cimetière des Innocents. 
These depictions were inspired by the “strange figures” engraved in the mysterious manuscript that helped Flamel on the quest for the Philosopher’s Stone.


onpowergraphchange is not registered when level starts.


does everything connect back everywhere back to a single mains connection?
or do we implement several smaller connected graphs within each scene
    this is more game-like

how did i envision the transformer connecting to the mains connection?
normal nodes in the network do not block transmission when they are destroyed, otherwise blowing up a gun turret might take out lights.
but, i do want blowing up the transformer to take out the lights.
so there is a distinction:
    * regular node
    * distribution node 
    * switch
    * mains

how do i envision "power map view"?
    a separate view superimposed over the scene
    in analogy with similar views: network, water, sensor nets
    when the view is active, mouse over components to view their information
        * power: on / off
        * enabled: yes / no
        * information: when this node is disabled, it will no longer distribute power to connected components
    mouse becomes a cursor
        this is important for network / hacking view, too
    is there a better / more visual / more intuitive way to represent the flow of power then?
        simple connections in the network are not sufficient?
        or else: all connections *are* power connections. no serial between disconnected nodes.
            in other words, go back to the original design of nodes interrupting power flow
            this design will be very spoke & wheel
            we can always move the lines around
    when does the view activate?


is there an exclusive cursor mode when the item is deployed?
    cyberdeck yes, AR goggles no?
    how to communicate to player that they can't shoot now?

design for cyber networks
    does hack originate from offscreen, as original idea?
        that was so that you could hack the building before going in.
        could offer a chanc


separate the player input / character controller setinput into interfaces
the other part of this code is pushing updates to animation - we can refactor this to use MVC / binding

unify sphereRobotAnimation and DirectionalBillboard
flip x in directional billboard

* head alignment
* wallpress camera alignment
* manual hacker
* fix binding to global player object
* wallpress zoom out
* jump controller

during slew time:
    turn to look
    don't shoot

searching:

1. looking in a direction versus searching a point
2. time evolution

looking in a direction:
    1. slew / look in direction
    2. look left, look right
    3. move some distance from original point towards the direction
    4. arrive at location, stop
    5. look left, look right

searching a location
    1. slew / look towards location
    2. move to location
    3. arrive at location
    4. look left, look right
    5. choose a new location near original location
    6. repeat 2-5

radioing to HQ
    1. find cover
    2. move
    3. operate radio
    transition to:
        player location unknown: search
        player location known: attack

we want to queue / schedule several routines in order, with transitions governed by timers or behavior
routines should have an update cycle and a way to check completeness
do we have a routine stack? what about branching?
more complex behavior would have the ability to transition to different routines depending.
    this makes it sound like routine logic controls the transition to the next routine.
    is the routine pushing this information or is it being polled by the state machine?

routine can publish when they are done
routine can publish transition to new state?

Q: levels:
1. individual routines (move, slew, etc)
2. overall state machine states (search direction, search location, radio hq)
3. state machine. time since last seen player, component references

something like: nested structure. update method, complete method
    method can publish finished, or transition to state

overhaul everything to be a behavior tree.
now we have to think: how is perception / sound going to be handled.
    1. use the tree logic and / or to handle perception states
    2. user perceptions to change textures

the question is: what do the state machine states correspond to?
it feels like they should be trees. recast the sequence as tree.


1. task tree updating
2. timed look toward task
3. timed look left / look right
4. retreiving player input from task

timed should become a decorator
use the namespace



major issue:
Evaluate() was the main chained thing that called sub nodes in the tree.
but Evaluate() isn't enough? Evaluate() returns a status, but I also need there to be a current active node 
findable from the root that is in control and returns PlayerInput.

return to using Evaluate()
but now the running node needs to somehow give playerinput
a timer decorator runs the child node and returns Running until time up
sequence is handled by a Sequence node

Evaluate takes a ref value
does Evaluate happen in an Update loop?

possibly, a Reset() mode but resetting can be handled by instantiating new state machine state

1. how to turn navigation etc. into task node

how to handle dynamic state in the behavior tree?
the normal solution seems to be to publish data to/from the tree. this feels clunky to me.
Ref<> is interesting.
TaskStatus<T>
TaskStatus(Owner)

what is the desired behavior?
1. look left, look right, move in. look around. move to a new spot? 
    if a new noise is heard, skip looking and move to that spot.
    how do we retarget? in behavior tree mode, it should look like:
    1. start path search aynchronous, running
    2. when path is found, next in sequence: move to target
    3. if path is not found, failed.

add movement to the root node sequence, but we're already off track:
1. resetting root node resets the entire sequence
2. not easy to retarget position without resetting root node.

how about: stop fighting the jank and use the getstate methods? it is the standard for behavior trees?
1. magic strings
2. unchecked casting (no strong)

TaskNode<T>(T context) where T: TaskNodeContext
then we can pass in 

playerinpu ref might be a bad idea?

now that we have that settled, the question is how to how to arrange the search AI as a behavior tree

the look-around branch is timer controlled. it consists of a sequence of timer controlled look directives.
    when to reset this timer? storing the timer in state allows for resetting? 
    recreating the branch each state change results in look-around loop?
        this is less important, we can have good control over state transition

sequence:
1. pathfind
2. navigate
have a Reset() method

sequence
1. move to key
2. select new random location for key
timer decorator involved?
timer decorator reset with repeater?

clean up and refactor and unify tasks
    unite all move to tasks
    remove reset?
    parent set data?

tune up ai behaviors
    1. add a delay to movement
        1. constantly changing target location while sphere is at old location until location is updated
        2. timer decorator will still be successful on the next time around 
    2. search more locations in noise?
    3. attack


visibility solutions

visibility shadows
    1. we must set texture orientation
    2. applying a shadow to the entire sprite is at odds with nice light effect
    3. combine regular shader and an overlay texture?
visibility rating
    1. use camera / vis probe surface as usual
        problem: shadows don't quite match up with expectations.
        can we make the solution more complex?
    2. use light probe
        problem: only works for baked lightmaps
    3. hand paint texture
        problem: immediacy of editing
        investigate editing texture in editor
        investigate terrain setting
    4. terrain
        can use in-editor painting
        can retrieve texture mix at point
        use this method for 

using terrains seems like an ideal solution for representing ground information
issues:
    1. discrete shadow levels (like thief)
        multiple textures?
        two textures with varying opacity?
            it is hard to control the opacity in editor
            hard to control precise boundaries
        multiple textures
            more work as more textures are added
            can use 3 textures plus overlap:
                shadow, mid, light


if (textureValues[0] > 0)
{
    source.PlayOneShot(GetClip(stoneClips), textureValues[0]);
}
if (textureValues[1] > 0)
{
    source.PlayOneShot(GetClip(dirtClips), textureValues[1]);
}
    

100 * ((0.2126 * 255) + (0.7152 * 255) + (0.0722 * 255))
255
25500 = 100 

100 * ((0.5 * 255) + (0.5 * 255) + (0.5 * 255))
38250


100 * ((0.5 * 255) + (0.5 * 255) + (0.2 * 255))
30600


20 = ++
30 = +++
40 = +++
45 = ++++
60+ = +++++


3 vs 10
B < 10: -
10 < B < 15: +
15 < B < 30: ++
30 < B < 60: +++
60 < B < 80: ++++
80 < B : +++++



set billboard
set albedo = white pixel
set emission
    emission map: single pixel white
    emission color: white + intensity 2
    emissio


1. put suspicion warnings as icons on bottom of screen in line with visibility indicator
    overall color and eye-catch can alert player on the fly


suspicion UI handler binds to GameManager
GameManager publishes when player suspicion changes
this will push updates to the various UI components
this could trigger an outline flash


1. billboarded color outliner
2. handle transitions between suspiciousness 

* fix audio suspicion
* aim & shoot broken
investigate routine
start with suspicion / gunout etc

AI test arena (VR theme)
    dummy targets
player health
loot 


some gun sounds, bullet impacts sound a lot better pitched up

1. new assets
    * AC unit and ducts
    * finish the other building
        * satellite dish
        * antenna
        * rooftop stuff
    wall / fence around level
    blinking red light
    fix the skybox (use blender)
    close skybox

    security camera
    more external boxes
    overhead pipes
    outside computer console

1.5 white interior environment
        office stuff
        trees & bushes
2. new spritesheet for player
    crouch to place C4
    crouch to pickup credstick
    hand graphic throw 
3. spritesheet for 7-11 worker
4. spritesheet for civilians

destructible AC unit
outline issues:
    crouching & head
    wall press scale orientation
* stutter in between  clipin and rack animation
use the same method in rifle as pistol (animation restart) to control fire interval and allow for trailing gunup
wallpress, crouch and gun: head is facing backwards (head always facing left)
question: can we adjust the stance when shooting smg, rifle?
    crouch / tactical?


legs UR idle
legs walking: ensure torso belt
torso unarmed walking: ensure torso belt not present?


1. move camera as we move cursor around
2. point gun once cursor is far enough away
3. right click to enter over the shoulder mode
4. scroll to zoom in and out.


fix wood window bottom
elevator interior
elevator panel
exit signs
stairwell
bathroom

carpet
wallC
wallC window
wallC window pane
desk
wallC front/back issue
chair: from back toward front, legs



1. use standard shader 
    can change opaque to transparent using shaderutils
    then can't use shader to determine distance from camera
2. use custom shader
    then we can use 
    v2f vert (appdata_t v)
    {
        v2f o;
        o.vertex = mul (UNITY_MATRIX_MVP, v.vertex);       
        o.screenPos = ComputeScreenPos(o.vertex);
        return o;
    }
    4th component is distance
    now we must switch between standard shader and custom interloper shader 
    use a standard surf shader and make it transparent


1. everything above player is shadows only.
2. everything between player and camera in a cylinder of radius r is switched to interloper shader.
3. objects closest to player are least transparent.

somehow, lerp the values.
we want to lerp from solid to transparent.
lerp in and lerp out.
to me, suggests that the parameter must be controlled from script, setting a value in the shader.
can we offload any calculation to the shader?
    1. set player world position. let shader calculate distance, occlusion, if above, if between player and camera.
        this is a good idea.
        if we do this, then it could all be done in shader except:
            1. it means everything must use interloper shader
            2. therefore everything using transparent tags means the depth is fucked
            3. therefore we simply must switch between shaders in script.
            4. therefore switching shaders is restricted to the things that should be hidden
            5. therefore hiding logic belongs to script.
    2. set lerping parameter. this is a separate consideration.

3 follows because the shader logic can't switch zwrite / tags on and off.
    functionally this is handled by switching shaders. so it is fundamentally that way.
    therefore we are using different shaders either way.

logic: everything in a cylinder coaxial with camera forward up to player position.

if we really need to, we can switch ceiling occlusion to be done by shader. but then we need:
    transparent shader
    opaque shader
    plant shader ?


1. InvokeRepeating instead of Update. 
2. use spherecollider for ceiling check.
    disable because above: target alpha = 0
3. use cylinder trigger for interloper check.
    disable because interloper: target alpha = decreasing with inverse radius of cylinder.
4. on make apparent:
    target alpha = 1

on change state:
    lerp parameter = 0
on update:
    if 
    lerp parameter += Time.deltaTime

*always lerp between 0 and 1, and use lerp parameter to control alpha.
*don't even lerp. just modify alpha parameter directly in code.


* cylinder collider
* don't fully disappear interloper
* target alpha set by distance



void Start()
 {
     _PlayerPos_ID = Shader.PropertyToID("_PlayerPos");
 }
 
 void Update()
 {
     Shader.SetGlobalVector(_PlayerPos_ID, gameObject.transform.position);
 }

 var target : Camera; function Update() { 
  var n = target.transform.position - transform.position;
  transform.rotation = Quaternion.LookRotation( n ); } 

  transform.rotation = Quaternion.LookRotation(n)

* destructible walls
* destructible computers
* hack network
* fix broken invisibility bug


problem:
target data is created by input controller in a way specific to top-down input.
    it doesn't work for aim, or wallpress
    also weird is the head animation (!) creates target data, separately.
    then target data is created in taskshoot in a totally different way.
the way target data is made should be dependent on state.
    because: in the one case, we are aiming from the camera down to the level, then projecting to a coplanar position with player, then aiming from player;
    in the other case, we are aiming from the camera across the player, toward a plane in front of player. 
    in the third case, we are AI trying to aim at last seen position.
    the only difference is the state we are in.
but if it is part of playerinput, then it can't be dependent on state, and it already is set before character controller.
so: let character controller create the targetdata as required?
this means: remove targetData from playerInput.
    if we do this, gunhandler is not an IInputReceiver.
    it can take playerinput Fire input, but should also take targetdata.
note all the instances of creating an empty PlayerInput only to wrap a targetData.

only things that reference playerinput.Fire.targetData:
    charactercontroller
    robot controller
    taskshoot
    gunhandler

note the robot controller already short-circuits this model. it uses a "shoot immediately" method that is not totally appropriate.

this should be okay.
main problem: the AI model is to pass around a reference to a PlayerInput and modify it as required.
in this sense, playerinput was supposed to be the master input that contained all information.
but it can't be if fire input is state dependent.
solution: pass around an AI input.
    AI input wraps both playerInput and TargetData.
    this is bad: now AI and player are not interchangeable.
by moving targetData calculation to controller, we are mixing model and control.
targetData should be fully determined at input stage, 

counterpoint: leave targetData as part of PlayerInput.
determine it at input stage.
let aim & top-down modes be distinguished in GameManager InputMode.
    but now we're tracking state in: character controller, and game manager.
    what happens when e.g. we enter aim mode but also press on the wall?
    in a single state, these are exclusive. otherwise we need extra logic for tracking all combinations of states in e.g. camera controller.

either gun input is in addition to controller input, or it is part of controller input.
how e.g. will player input work for the sphere robot?
    we can say this is the kind of architecture thing i dont want to worry about in this game but if not, what is the point of unified playerInput?
question: is right click aim a feature of the input (direction i'm heading in) or is it a feature of the character?
i.e. if we control the robot and right click it should enter aim mode right?
    then the camera control should be referencing gamemanager input state, not character state.

* how to fix headAnimation?
* aimindicatorhandler?
* switch back and forth from left / right when cursor pans left / right
* controllability
    * right-click for ove the shoulder aiming
    * camera moves to point toward the aimpoint
* character & head orient in correct direction when aim mode
* shoot toward cursor
* camera a little above, oriented down
* camera moves slightly in direction of cursor
* turn left & right when cursor near the edge ..?
- animation shows recoil
- display different UI when in aim mode
- laser pointer attachment
- flashlight attachment
- don't clip camera through wall
- UI: gun wireframe in lower-right corner.
- gun inaccuracy in over the shoulder mode should be constant angular size
- head look around if player has been idle
- make elevator
- why do gibs fall through the wall/floor?
- clearsight InvokeRepeating
- clearsight OverlapSphereNonAlloc
- clearsight don't update ceiling calculation when in the air
- blinking arrow indicator when switching perspectives
- perhaps a smoother transition to/from aim mode?
- TODO: configurable scale, possibly involve aspect ratio
- ceiling clearsighter shadowsonly
- fog of breath

make a real mission. 
    * civilian man
        * draw base
        * draw guns
    * civilian woman
        * draw base
        * draw guns
    1. 7-11 worker sprite
        draw base
        draw guns
    4. security guard
        draw base
        draw guns

fix head
    how to fix head?
    essentially, we want to place the custom head at the appropriate point in each part of the relevant spritesheet.
    1. extend the head spritesheet and export the proper head in the proper position in the spritesheet, like we do with torso / legs.
    2. define a set of data points per frame that define where the head should be, and which head sprite.
        if we hardcode this, then every spritesheet from now to finish has to have the same points or we break compatibility.
        idea: leverage unity editor
            if we can select the torso sprite, then select head sprite and adjust position while seeing in the editor.
            this would be a tool with unity editor code.
            set up the design, then export a data object.
            load the data object with 

it's billboarded. this is the difference between the editor and runtime.
although the character is rotated, we want to de-rotate the sprites.
offset x, y must always be set in the plane normal to the camera. this is why the trick works.
    by turning the transform rotation to that of the camera, we align the plane of the camera. 
    we then set the offset using local transform coordinates: this would work in any order actually.
    we record the world position, then rotate back.

Q: so why does this fail on the wallpress mode? 
    we turn the transform to the camera plane, away from the camera.
    once we rotate back and allow the wallpress to orient, we are faced toward the camera.
    billboarding is disabled, so we are oriented opposite of normal billboard.
Q: why does it work normally?
    we rotate the transform to the camera plane.
    we set the world position of the head to match where it should be during billboard orientation up to projection.
    the transform is rotated to whatever direction it points in.
    the rotation doesn't matter because billboarding is applied and the world positioning simulates the correct offset.
    if the sprite is flipped, the offset is incorrect! so we adjust it at this point.
        it is incorrect because the choice of orientation at the beginning was just the camera plane.
        if sprite renderer is flipped, we could choose the inverse orientation.
Q: what is the proper solution?
    we need a billboard & non-billboard solution?


* redesign data structure so it can generalize to multiple skins
* make it easier to select the next torso sprite (spritesheet parameter?)
* sprite data: 
    * override head direction
    * head in front of torso 
* editor: no way to inspect torso data after written.
* save and load data functionality.
* generalize to gun
* fix smg and shotgun head positioning
? prevent invisibility for some objects
? UI: draw a circle for inaccuracy? cone?
* disable run in aim mode
* crack is black
* crouch graphics are wrong
* rotation orientation issues
* sphere walks on people
* don't shake camera when shooter is not player
* reloading for animated character
* searching AI hears gunshot?
* wallpress orientation is wrong
* head looking in correct direction
* muzzle flash when looking head-on
* look toward noise
* AI does wallpress
* aim mode start from lookat
* look around while walking
* head on a swivel 
* transition back to patrol
* head behavior changes with AI state
* handle the case when multiple gunshots are heard repeatedly.
* crawl animation slower
* new idea: instead of stickiness timer, in crouch mode, input just makes the character slew toward direction.
* we never noticed the weird turning effects because it was never possible to turn in crouch mode.
* subtly aim up & down
* smoothly interpolate between left and right focus points.
* narrower field of view and further distance
* ensure torso bob is correct
* wallpress head sprite is messed up
* wallpress left/right is weird
* head position when crouching in wallpress is wrong
* head position when laying on floor is wrong
* wallpress when crawling
* slower turn radius when crawling
* only rotate when moving while crawling
* make crawl nonuniform speed
* camera wall clipping
* crouch, crawl sounds
* z-fighting between torso, legs, head
* character hurtable
* blood splatter on hit
* scale blood splatter random
* blood splatter
* fix unlit billboarding
* look direction not working
* blood particle effects
* ejected in the direction of the bullet
* blood splat on walls
* blood pooling
- hit reaction animation / graphic ?
* object pooling for particle effects
* corpse
* fix jump crouch sound
* VR environment
* crawl idle head position
* fix crouch gun animations
* put player audio source on a separate mix from other audio sources
    * support mixers in setupaudiosource
    * enemy gunshots louder
* hurtable impact
    * turn to face bullet
    * shake
* fix clearsighter
* verify that sparks still work properly
* verify that sphere robot still works properly
* graphics:
    * combat test arena VR
    * blood particle
    * death graphic
        * import spritesheet
        * define new skin components
    * corpse graphic
* AI: show question mark when startled by suspicious sound, look in directions
* AI: when in combat mode, pay attention to sounds
* in investigate mode, sounds should have much smaller radius
* head should look around when in search mode.
* crouching behind cover should be safe.
* visually indicate stealth / allow player to melt into shadows
* adjust stealth parameters until it feels like it makes a difference
* better aim mode: 
    * leave aim mode snap to isometric direction
    * get character out of the way of aim
    * find some fixed relation between distance and depth of field. ?
    * don't crawl in aim mode
* sparks on destructible walls
* guard can't see over midheight obstacle
* adjust walk animation speed with movement

graphical issues:
    smg torso face left, head face down looks odd
    female walk left / right torso offset is incorrect?
aim: swing into position, then subtly zoom in to focus on reticle
    accompanied by rotating reticle element
impact knockback
    slide, kneel, get up?
fix bullethole prefab / material / decal system 
    allow different materials or different prefabs accordingly
tasklookAt returns running, should return success?
less intense wall sticking?
creep button (crawling is?)

UI:
    blink cursor when reaching maximum aim
    bigger aim reticle
    health display
    square drops in on targets, stats appear in side 

damage result addition is weird
leaves and junk in the street that blows around
allow independent level data
prevent extreme zoom maneuvers with lerping
position call-out
when spotted, zoom camera out to show aggressor
    slow time a little bit
fix camera position in wallpress mode when near edge
glass break fx
AI routine for reloading and racking?
don't do outline highlight if i am not the player

gibs from explosions
corpse can be shot / exploded
apply skin graphics to corpse
better reaction to hearing noise in search / combat when noise is not suspicious
gestural aiming with auto-lock

don't destroy on dead; recall to pool.
spawn new NPC 
interface for designing multiple scenarios
    danger room
    spawning enemies
    enemy count
    victory conditions